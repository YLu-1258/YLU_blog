{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- title: \"'CS61B: Lecture 11'\"\n",
    "- author: alex\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [CS61B]\n",
    "- date: 2024-02-14 1:00:00 -0800\n",
    "- math: true\n",
    "- tags: [CS61B, Asymptotics, JAVA]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asymptotic Analysis\n",
    "- Ex: Given a sorted array, determine if the array contains any duplicates.\n",
    "    - Silly approach: Check every element to each other, quadratic time.\n",
    "    - Better approach: Compare each element with the element after itself, linear time.\n",
    "- To measure efficiency of a program:\n",
    "    - Define a metric to evaluate the efficiency. Can be runtime, memory, etc.\n",
    "    - Provide a mathematical function to classify the algorithm.\n",
    "\n",
    "# Techniques for Measuring Program Efficiency\n",
    "- We could physically measure the time it takes for the program to run.\n",
    "    - However, different computers have different runtimes.\n",
    "    - Different programming languages also have different efficiencies.\n",
    "    - We want to measure the inherent efficiency of the algorithm itself.\n",
    "- We can count the possible operations for an algorithm.\n",
    "    - Machine independent and also tells us how algorithm grows.\n",
    "    - The granularity of the operations also matters.\n",
    "    - Tedious to calculate and not a function.\n",
    "- For each input size N, select one specific input to represent that input size. Count the number of operations for that input.\n",
    "    - Common choises are the worst case input (the input that takes the most operations) and the best case input (the input that takes the least operations).\n",
    "    - This is now a function, but it's still not too easy to compare between different algorithms. hewo\n",
    "\n",
    "# Classifying Efficiency\n",
    "- Program efficiency really only cares about order of growth, or about how efficiency scales.\n",
    "- For smaller inputs, O(N^2) may be faster than O(N) based on constants, but eventually O(N^2) will overtake O(N).\n",
    "- If we add up all of the general number of operations for some program, the term with the highest order dominantes over all other terms\n",
    "    - Ex: 0.0000001*2^N+23324234234N^2+123123123N+1230092108301820381923\n",
    "    - Is still a 2^N Order of growth algorithm.\n",
    "- We may group together all algorithms of a certain order of growth for their worst case efficiency into the Big-Theta notation.\n",
    "    - ϴ(1), ϴ(N), ϴ(N^2), ϴ(2^N), ϴ(logN), ϴ(NlogN), ϴ(N!)\n",
    "\n",
    "# Simplifying the Analysis Process\n",
    "- We treat anything that takes constant time as a single operation.\n",
    "- Figure out the order of growth by intuition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "java",
   "pygments_lexer": "java",
   "version": "17.0.14+7-Ubuntu-122.04.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
